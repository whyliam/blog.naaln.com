---
layout: post
title: L18_社会性的拐点
date: 2023/04/30/ 20:00:00
categories:
- 资讯
tags:
- NewsLetter
---

- 结构性改变才能真正改变社会和产业，而这种改变往往是一类大型成本从边际走向固定；模型的成本现在也正在发生同样的转变，大模型将成为技术核心和产业化基础，让个人见解变得至关重要。
- 人类和 GPT 这类语言计算模型是高度理性化的结晶，在人对其进行理解过程中，我们应该转换视角思考人类作为一个语言机器时的关系特征，以此探讨符号智能与物体之间可能存在的空缺及感官经验上的差异。同时，GPT 可以被看作一种在字符库中漂浮的智能，尽管它可以回答各种问题，但永远缺乏涉及到真实物体的直接关系，因此其知识只能是语言化的。
- 寻找自己喜欢的工作其实不易，但很重要。父母对职业不满可能影响孩子寻找喜欢的工作；名利双收的职业是最危险的，因为年轻人容易被权利、前途和声望蒙蔽而迷失方向；不能总有人做讨厌的工作，选择一个值得追求的宏伟目标才会配得上你的努力；钱越多的工作越需要付出全部的精力，加上高生活开支，容易丧失再选择所爱的可能。

---

## 一个拐点：社会性拐点的核心是一项大型成本从边际变成固定

![Request for Business Intelligence and Assistance](https://pics.naaln.com/blog/2023-05-01-7b591a.jpg-basicBlog)

**一定要记住，任何改变社会、改变产业的，永远是结构性改变。这个结构性改变往往是一类大型成本，从边际成本变成固定成本。**

我在 CMU 念书开车离开匹茨堡出去，一张地图 3 美元，获取信息很贵。今天我要地图，还是有价钱，但都变成固定价格。Google 平均一年付 10 亿美元做一张地图，但每个用户要获得地图的信息，基本上代价是 0。也就是说，获取信息成本变 0 的时候，它一定改变了所有产业。这就是过去 20 年发生的，今天基本是 free information everywhere（免费的信息无处不在）。

Google 为什么伟大？它把边际成本变成固定成本。Google 固定成本很高，但它有个简单商业模式叫广告，它是世界上高盈利、改变世界的公司，这是拐点关键。

**今天 2022-2023 年的拐点是什么？**它不可阻挡、势不可挡，原因是什么？一模一样。模型的成本从边际走向固定，因为有件事叫大模型。

模型的成本开始从边际走向固定，大模型是技术核心、产业化基础。OpenAI 搭好了，发展速度爬升会很快。为什么模型这么重要、这个拐点这么重要，因为模型和人有内在关系。**我们每个人都是模型的组合。**人有三种模型：

1. 认知模型，我们能看、能听、能思考、能规划；
2. 任务模型，我们能爬楼梯、搬椅子剥鸡蛋；
3. 领域模型，我们有些人是医生，有些人是律师，有些人是码农。

我们对社会所有贡献都是这三种模型的组合。每个人不是靠手和腿的力量赚钱，而是靠脑袋活。

简单想一想，如果你没有多大见解，你的模型能力大模型都有，或者大模型会逐步学会你所有的模型，那会怎样？**——未来，唯一有价值的是你有多大见解。**

**相关延伸**：
[陆奇最新演讲实录：我的大模型世界观 (qq.com)](https://mp.weixin.qq.com/s/_ZvyxRpgIA4L4pqfcQtPTQ)

---

## 当我们谈论知识时，我们在谈论什么？

![img](https://pics.naaln.com/blog/2023-05-01-919391.png-basicBlog)

有句话叫人体解剖是猴体解剖的钥匙，只有当一种新的形态被人认识的时候，之前的现象才被理解为它的征兆，理解为一种潜能。所以当一种被认为是节点性的新事物出现的时候，很有可能就是理解人类自身的一个最佳时期。我们不应该错过通过它来重新理解人。然后再反观他，可能会有更深的启发。

这个比方涉及的是 GPT 和人关系特别密切的一个层面。人和其他生物最大的区别就是人是一种符号，动物是一种高度语言化的生物。那么 GPT 它是一个语言计算模型，它的存在方式就是不断的语言生成过程，是人类高度理性化的一个结晶。我们可以想象理性这个结晶现在脱离了感知觉的维度，开始独立出来自行运转。那么我们可以转换一下视角，我们不用总是去想 GPT 会怎么样，越来越像人，而是去思考人在何种程度上是一个语言机器。人类知识的绝大部分都是语言化的知识可言说的知识是符号的知识。这种知识和作为物质的，我们到底是一种什么样的关系呢？

如果我们平时把水杯、桌子这种东西叫「物体」，那么我们也可以把 GPT 这类的东西叫做「词体」。因为他是一个通过语词回答问题，完成任务的一个功能体。关键问题不在于他现在的能力怎么样，以后会有多厉害，而在于他回答问题的方式。这个原理他自己也解释的很清楚，他所有的回答都是基于与词符号之间的计算词与词之间的数学关系、集合概率、次序、拓扑等关系。

你可以想象不是他在说话，而是话在说他。其实在很大程度上人也是一样的。很多时候并不是我们在说话，而是在被话说，特别是吵架的时候。语词字符就是一些计算规则，而话语就是语词的内部运算法则，通过触发被生成显示出来。

很多时候他会胡说八道，给出非常荒谬的答案，这并不是计算错误，而是这个计算的结果不符合人类的日常经验而已。这个可以用人类做梦来大概理解一下我们做梦的情节，对于日常理性来说是非常荒诞的。我们醒着的时候，我们会这样去想，是因为我们醒着的时候需要我们来组织这些预测。但在睡着的时候，你可以想象，平时那些印象作为语词单元，它是在自行运作的。所以这个程序它只要符合语词之间的语法，它自己就能跑起来了。比如楼房是弯曲的，苹果是流淌的，被鼻子哭了等等等等。也就是这个句子，它的语法对就行了，并不用顾忌到日常经验。所以梦的语言经常是自己在那儿胡说八道。

因为 AI 本身它没有感官经验，它的素材都是大数据训练的。所以说如果只是处理字符间的运算，那就很像是在说梦话。这些都要靠大量的人工和后面的数据来不断的纠正图片。随着数据学习的不断叠加，算法越来越复杂，人肯定是没有办法知道一个答案。在 AI 的内部具体运算过程，也就是说对于一些复杂的问题，AI 他到底是怎么想出来的。所以我猜以后可能会有这样一种职业，就是 AI 的金融科技师。不过这不是今天的话题，我们先答错。那么 GPT 这类的词解是一个漂浮在字符库中的智能，是一个没有吃过苹果，但是能够给你关于苹果一切知识的智能体，然后永远缺乏一个及物的维度，也就是和物的直接关系。所以这种知识只能是语言化的知识和言说的知识。

**相关延伸**:
[【GPT与神学】当我们谈论知识时，我们在谈论什么？](https://www.bilibili.com/video/BV1Wh41137oS/?vd_source=aaf97962a737bacfe259a63135a90d72)

---

## 如何才能去做喜欢的事情

![The Only Way To Do Great Work Is To Love What You Do - Ben Francia](https://pics.naaln.com/blog/2023-05-01-fa00b4.jpg-basicBlog)

一个朴素的道理「**喜欢一件事才能做好它**」，但是如何找到自己喜欢的事情，确实很难。我定期的也会问我自己，到底目前在做的事情是否是自己喜欢的事情。

Paul Graham 在文中提到了很多我们觉得习以为常，但是深究下来却值得思考的情况：

- 如果父母都不喜欢自己的工作，那么孩子如何能找到自己喜欢的工作呢？
- 真正的危险来自于名利双收的职业，例如从事企业法律或者医学工作。一份既有保障又有前途的工作，再加上一点可以不劳而获的声望，才是对青年人最大的威胁，因为他们还没开始思考什么是他们真正喜欢的。
- 不能每个人都做自己喜欢的事，总得有人做令人讨厌的工作。这种自我安慰的言论在身边也屡见不鲜，因为能很好的给自己找到一个推脱的借口，然后一代一代人这样传下去。但如苏世民所说「做大事和做小事的难易程度是一样的，所以要选择一个值得追求的宏伟目标，让回报与你的努力相匹配」
- 钱越多的工作越危险，因为要付出全部精力。环境对于一个人的塑造是巨大的，辩证的说，在一个回报更多的地方意味着更多的责任，而更多的责任让你不得不付出更多的精力（996 不也是这种情况下诞生的么？拿双倍工资付出三倍劳动）。加上如果不慎重让自己的生活开支因此提的很高，整个人就被工作和生活双重绑架，丧失了再选择所爱的可能。

**相关延伸**：
[How to Do What You Love (paulgraham.com)](http://www.paulgraham.com/love.html)

---

> 关注不迷路 [博客](https://blog.naaln.com/)｜[竹白](https://space.zhubai.love/)
